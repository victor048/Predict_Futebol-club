{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Campeonato-Brasileiro.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNOAb2Ud9DIzJxq31Uf/ZFE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victor048/Predict_Futebol-club/blob/main/Campeonato_Brasileiro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ObqYqZ2FUUBs"
      },
      "outputs": [],
      "source": [
        "#importar bibliotecas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score , f1_score, precision_score, recall_score\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.model_selection import  GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import scale\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lendo o arquivo BRAS.csv\n",
        "#O arquivo utilizado foi baixado do site www.football-data.co.uk, que agrega informações de diversos campeonatos\n",
        "#ao redor do mundo.\n",
        "\n",
        "data=pd.read_csv('BRA.csv',delimiter=',')\n",
        "\n",
        "#Verificando as 5 primeiras linhas do arquivo a ser utilizado\n",
        "display(data.head())\n",
        "\n",
        "#Notes for football data\n",
        "\n",
        "#Country = país do campeonato\n",
        "#League = nome da liga\n",
        "#game_id = id do jogo\n",
        "#Season = temporada\n",
        "#date = data do jogo\n",
        "#Time = hora do jogo\n",
        "#Home = Time da casa\n",
        "#home_id = id do time da casa\n",
        "#Away = time visitante\n",
        "#Away_id =  id do time visitante\n",
        "#HG = Gols do time da casa\n",
        "#AG = Gols do time visitante\n",
        "#Res = Resultado do jogo (D=Draw, H=Home win, A=Away win)\n",
        "#PH = probablidade vitória time da casa provida pela Pinacle (casa de aposta inglesa)\n",
        "#PD = probablidade empate provida pela Pinacle (casa de aposta inglesa)\n",
        "#PA = probablidade vitória time visitante provida pela Pinacle (casa de aposta inglesa)\n",
        "#MaxH = probablidade vitória time da casa provida pela OddsPortal (casa de aposta inglesa)\n",
        "#MaxD = probablidade empate provida pela OddsPortal (casa de aposta inglesa)\n",
        "#MaxA = probablidade vitória time visitante provida pela OddsPortal (casa de aposta ingles\n",
        "#AvgH = probablidade média de vitória em casa provida pela OddsPortal (casa de aposta inglesa)\n",
        "#AvgD = probablidade média de empate provida pela OddsPortal (casa de aposta inglesa)\n",
        "#AvgA = probablidade média de vitória pelo time visitante provida pela OddsPortal (casa de aposta inglesa)\t"
      ],
      "metadata": {
        "id": "TDMZrElzXl0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Explorando os dados\n",
        "#Base de dados de dos campeonatos de 2012 a 2017\n",
        "\n",
        "matches = data.shape[0]\n",
        "\n",
        "features = data.shape[1] -1 #Retirando a coluna Resultado\n",
        "\n",
        "home_win = len(data[data.Res==1])\n",
        "away_win = len(data[data.Res==2])\n",
        "draw = len(data[data.Res==0])\n",
        "val=[home_win,away_win,draw]\n",
        "\n",
        "win_rate = (float(home_win)/(matches)) *100\n",
        "\n",
        "print ('Total de jogos: ', matches)\n",
        "print ('Total de colunas: ', features)\n",
        "print ('Total de jogos ganhos em casa: ', home_win)\n",
        "print ('Total de jogos ganhos pelo visitante: ', away_win)\n",
        "print ('Total de jogos empatados: ', draw)\n",
        "print ('Percentual de jogos ganhos em casa: {:.2f}%'.format( win_rate ))\n",
        "\n",
        "#Podemos notar que o \"fator casa\" é importante , sendo que em quase 50% do jogos são ganhos pelo time da casa."
      ],
      "metadata": {
        "id": "WHj__Tv5ZXXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizando os dados\n",
        "\n",
        "x = np.arange(3)\n",
        "plt.bar(x, val)\n",
        "plt.xticks(x, ('Home', 'Away', 'Draw'))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iy6RMmqPZhzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preparando os dados\n",
        "\n",
        "\n",
        "#Deixar somente as variáveis numericas \n",
        "num_data = data.drop(['Country','League','Season','Date','Time','Home','Away'],1)\n",
        "\n",
        "display(num_data.head())"
      ],
      "metadata": {
        "id": "m8facrMtZuV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#separa as features \n",
        "features = num_data.drop(['Res'],1)\n",
        "\n",
        "\n",
        "#separa as labels\n",
        "labels = num_data['Res']\n",
        "\n",
        "print('Features')\n",
        "print (features.head())\n",
        "\n",
        "print ('=========')\n",
        "\n",
        "print ('Labels')\n",
        "print (labels.head())"
      ],
      "metadata": {
        "id": "y7sRZuujZ0a1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Escoolhendo as melhores features com Kbest\n",
        "\n",
        "features_list = ('HG','AG','PH','PD','PA','MaxH','MaxD','MaxA','AvgH','AvgD','AvgA')\n",
        "\n",
        "k_best_features = SelectKBest(k='all')\n",
        "k_best_features.fit_transform(features, labels)\n",
        "k_best_features_scores = k_best_features.scores_\n",
        "raw_pairs = zip(features_list[1:], k_best_features_scores)\n",
        "ordered_pairs = list(reversed(sorted(raw_pairs, key=lambda x: x[1])))\n",
        "\n",
        "k_best_features_final = dict(ordered_pairs[:15])\n",
        "best_features = k_best_features_final.keys()\n",
        "print ('')\n",
        "print (\"Melhores features:\")\n",
        "print (k_best_features_final)"
      ],
      "metadata": {
        "id": "BIfyZgGKZ5Gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#separa as features com base nas melhores features para treinamento\n",
        "features = num_data.drop(['Res','game_id','home_id','Away_id', 'AG','PD','PH'],1)\n",
        "\n",
        "\n",
        "#separa as labels para treinamento\n",
        "labels = num_data['Res']\n",
        "\n",
        "print('Features')\n",
        "print (features.head())\n",
        "\n",
        "print ('=========')\n",
        "\n",
        "print ('Labels')\n",
        "print (labels.head())"
      ],
      "metadata": {
        "id": "W8hjRHIdZ-yI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizando os dados de entrada(features)\n",
        "\n",
        "# Gerando o novo padrão\n",
        "scaler = MinMaxScaler().fit(features)\n",
        "features_scale = scaler.transform(features)\n",
        "\n",
        "print ('Features: ',features_scale.shape)\n",
        "print (features_scale)"
      ],
      "metadata": {
        "id": "aG4pA0BfaHTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Separa em treinamento e teste\n",
        "#Separação manual para manter a ordem cronológica, uma vez que temos informação temporal. \n",
        "#Treino linhas [:1932]\n",
        "#Teste linhas [1932:2155]\n",
        "#previsão linhas [2155:2280]\n",
        "\n",
        "\n",
        "X_train = features_scale[:1932]\n",
        "X_test = features_scale[1932:2155]\n",
        "y_train = labels[:1932]\n",
        "y_test = labels[1932:2155]\n",
        "\n",
        "print( len(X_train), len(y_train))\n",
        "\n",
        "print( len(X_test), len(y_test))"
      ],
      "metadata": {
        "id": "kXfy6nFiaLve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Treinando e testando os modelos\n",
        "print ('LogisticRegression')\n",
        "\n",
        "\n",
        "clf_LR = LogisticRegression(multi_class='multinomial',max_iter=2000)\n",
        "clf_LR.fit(X_train, y_train)\n",
        "pred= clf_LR.predict(X_test)\n",
        "\n",
        "lg_acc = accuracy_score(y_test, pred)\n",
        "f1=f1_score(y_test,pred,average = 'micro')\n",
        "print ('Acurácia LogisticRegression:{}'.format(lg_acc))\n",
        "print ('F1 Score:{}'.format(f1) )"
      ],
      "metadata": {
        "id": "sgLgp0FuaRRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testando LogistRegression hyper parameters\n",
        "\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
        "\n",
        "search = GridSearchCV(LogisticRegression(max_iter=1000), param_grid)\n",
        "\n",
        "search.fit(X_train,y_train)\n",
        "clf = search.best_estimator_\n",
        "pred= clf.predict(X_test)\n",
        "lg_acc = accuracy_score(y_test, pred)\n",
        "\n",
        "\n",
        "f1=f1_score(y_test,pred,average = 'macro')\n",
        "\n",
        "print ('Acurácia LogisticRegression:{}'.format(lg_acc))\n",
        "print ('F1 Score:{}'.format(f1) )\n",
        "\n",
        "print (clf)"
      ],
      "metadata": {
        "id": "WOAAWyrcaVrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Treinando e testando os modelos\n",
        "print ('SVC')\n",
        "\n",
        "\n",
        "clf = SVC()\n",
        "clf.fit(X_train, y_train)\n",
        "pred= clf.predict(X_test)\n",
        "\n",
        "svc_acc = accuracy_score(y_test, pred)\n",
        "f1=f1_score(y_test,pred, average='micro')\n",
        "print ('Acurácia SVC:{}'.format(svc_acc))\n",
        "print ('F1 Score:{}'.format(f1) )"
      ],
      "metadata": {
        "id": "2d9Oa6jZai3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testando SVC hyper parameters\n",
        "\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
        "\n",
        "search = GridSearchCV(SVC(), param_grid)\n",
        "\n",
        "search.fit(X_train,y_train)\n",
        "clf_SVC = search.best_estimator_\n",
        "pred= clf_SVC.predict(X_test)\n",
        "acc = accuracy_score(y_test, pred)\n",
        "\n",
        "\n",
        "f1=f1_score(y_test,pred,average = 'micro')\n",
        "\n",
        "print ('F1 Score:{}'.format(f1))\n",
        "\n",
        "print ('Acurácia LogisticRegression:{}'.format(acc))\n",
        "\n",
        "print(clf_SVC)"
      ],
      "metadata": {
        "id": "_o9qdnikap5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Treinando e testando os modelos\n",
        "print ('Decision Tree')\n",
        "\n",
        "\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "pred= clf.predict(X_test)\n",
        "\n",
        "dt_acc = accuracy_score(y_test, pred)\n",
        "f1=f1_score(y_test,pred, average='macro')\n",
        "print ('Acurácia Tree:{}'.format(dt_acc))\n",
        "print ('F1 Score:{}'.format(f1) )\n",
        "\n",
        "\n",
        "n_estimators = [10, 50, 100, 200]\n",
        "max_depth = [3, 10, 20, 40]"
      ],
      "metadata": {
        "id": "Z5mP2AzDavIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testando Decision tree hyper parameters\n",
        "print ('Decision Tree')\n",
        "\n",
        "param_grid = {\n",
        "    'max_depth': [80, 90, 100, 110],\n",
        "    'max_features': [2, 3],\n",
        "    'min_samples_leaf': [3, 4, 5],\n",
        "    'min_samples_split': [8, 10, 12]\n",
        "    \n",
        "  \n",
        "}\n",
        "\n",
        "search = GridSearchCV(DecisionTreeClassifier(), param_grid)\n",
        "\n",
        "search.fit(X_train,y_train)\n",
        "clf = search.best_estimator_\n",
        "pred= clf.predict(X_test)\n",
        "dt_acc = accuracy_score(y_test, pred)\n",
        "\n",
        "\n",
        "f1=f1_score(y_test,pred,average = 'micro')\n",
        "\n",
        "print ('Acurácia Decision Tree:{}'.format(dt_acc))\n",
        "print ('F1 Score:{}'.format(f1) )\n",
        "\n",
        "print (clf)"
      ],
      "metadata": {
        "id": "ugA16ZqsaznM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Treinando e testando os modelos\n",
        "print ('Naive baeys')\n",
        "\n",
        "\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train, y_train)\n",
        "pred= clf.predict(X_test)\n",
        "\n",
        "nb_acc = accuracy_score(y_test, pred)\n",
        "f1=f1_score(y_test,pred, average='micro')\n",
        "print ('Acurácia Naive baeys:{}'.format(nb_acc))\n",
        "print ('F1 Score:{}'.format(f1) )"
      ],
      "metadata": {
        "id": "bmMhdAdLbFSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Executando a previsao\n",
        "\n",
        "previsao=features_scale[2155:]\n",
        "\n",
        "game_id_full=data['game_id']\n",
        "game_id=game_id_full[2155:]\n",
        "\n",
        "res_full=data['Res']\n",
        "res=res_full[2155:]\n",
        "\n",
        "\n",
        "pred=clf_SVC.predict(previsao)\n",
        "\n",
        "df=pd.DataFrame({'real': res, 'previsao':pred, 'game_id':game_id})\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "id": "Uu604w_RbLR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#confusion Matrix\n",
        "\n",
        "df=pd.DataFrame(df,columns=['real','previsao' ])\n",
        "\n",
        "cf_matrix=pd.crosstab(df['real'], df['previsao'], rownames=['real'] , colnames=['previsao'])\n",
        "\n",
        "sns.heatmap(cf_matrix, annot=True, cmap='Blues')"
      ],
      "metadata": {
        "id": "MBiHg7e3bYCY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}